{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensegment: default program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from default import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Write some beautiful documentation of your program here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose spain\n",
      "this is a test\n",
      "who represents\n",
      "experts exchange\n",
      "speed of art\n",
      "unclimatechangebody\n",
      "we are the people\n",
      "mentionyourfaves\n",
      "now playing\n",
      "the walking dead\n",
      "follow me\n",
      "we are the people\n",
      "mentionyourfaves\n",
      "check domain\n",
      "big rock\n",
      "name cheap\n",
      "apple domains\n",
      "honesty hour\n",
      "being human\n",
      "follow back\n",
      "social media\n",
      "30secondstoearth\n",
      "current ratesoughttogodown\n",
      "this is insane\n",
      "what is my name\n",
      "is it time\n",
      "let us go\n",
      "me too\n",
      "nowthatcherisdead\n",
      "advice for young journalists\n"
     ]
    }
   ],
   "source": [
    "Pw = Pdist(data=datafile(\"data/count_1w.txt\"))\n",
    "segmenter = Segment(Pw)\n",
    "with open(\"data/input/dev.txt\") as f:\n",
    "    for line in f:\n",
    "        print(\" \".join(segmenter.segment(line.strip())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Do some analysis of the results. What ideas did you try? What worked and what did not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Default Result Analysis\n",
    "\n",
    "We found out that for the default unigram result, it does especially bad at generating some irrationally long word like \"unclimatechangebody\", and \"howtobreakupin5words\". That is to say, giving words unseen in the corpus data (count_1w.txt) a uniform probability of `1/N` is not a good idea. It basically means when facing something like \"uncliamte...\", and if both \"un\" and \"unclimate\" are both unseen in the corpus, the language model will think \"un\" and \"unclimate\" have the same probability.\n",
    "\n",
    "To proof our assumption is right, we first change the probability from `1/N` to `100/N`, and we think this will make the result score even worse casue the language model accept the long unseen word even more than before. And the dev score drops from 0.82 to 0.72."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add an adaptive function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoid_long_words(word, N):\n",
    "    \"Estimate the probability of an unknown word.\"    \n",
    "    return 10./(N * 10**len(word))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"some scripts\"\n",
    "\n",
    "\t# passing the adaptive function to the Pdist function\n",
    "    Pw = Pdist(data=datafile(opts.counts1w), missingfn= avoid_long_words)\n",
    "\n",
    "    segmenter = Segment(Pw)\n",
    "    with open(opts.input) as f:\n",
    "        for line in f:\n",
    "            print(\" \".join(segmenter.segment(line.strip())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, we added an function that returns a probability given the length of the input word. When the word is one character longer, the probability is 10 times smaller than the default `10/N` value. This adaptive function avoids the language model to generate extremely long segementation result.\n",
    "\n",
    "After we add this one-line function, and pass it to the `Pdist` class, the dev score raise from 0.82 to 1.0, which is a very ideal result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
